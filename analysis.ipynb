{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaee18-8898-4843-aed9-d3941df6c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "confidence_map = {\n",
    "    \"Almost no chance\": 0.0,\n",
    "    \"Highly unlikely\": 0.1,\n",
    "    \"Chances are slight\": 0.2,\n",
    "    \"Unlikely\": 0.3,\n",
    "    \"Less than even\": 0.4,\n",
    "    \"Better than even\": 0.5,\n",
    "    \"Likely\": 0.6,\n",
    "    \"Very good chance\": 0.7,\n",
    "    \"Highly likely\": 0.8,\n",
    "    \"Almost certain\": 0.9\n",
    "}\n",
    "\n",
    "def parse_conf(text: str) -> float:\n",
    "    proc_text = text.lower().strip().replace(\" \", \"\")\n",
    "    for conf_text, conf in confidence_map.items():\n",
    "        if conf_text.lower().replace(\" \", \"\") in proc_text:\n",
    "            return conf\n",
    "    return -1\n",
    "\n",
    "def load_data(exp: str, model_size: str) -> List[Dict]:\n",
    "    with open(f\"./data/doubt-{exp}-{model_size}.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "exps = [\"baseline\", \"1_4\", \"mid\", \"3_4\", \"end\"]\n",
    "model_sizes = [\"1.5\", \"7\", \"14\"]\n",
    "\n",
    "rows = []\n",
    "for exp in exps:\n",
    "    for model_size in model_sizes:\n",
    "\n",
    "        data = load_data(exp, model_size)\n",
    "\n",
    "        for d in data:\n",
    "            \n",
    "            conf = parse_conf(d[\"confidence\"])\n",
    "            \n",
    "            reason = d[\"text\"].split(\"<think>\")[-1].split(\"</think>\")[0]\n",
    "            \n",
    "            if conf == -1:\n",
    "                # If parsing failed don't include the data point\n",
    "                # the text is corruped or the context length was\n",
    "                # exceeded while generation\n",
    "                continue\n",
    "                \n",
    "            rows.append({\n",
    "                \"exp\": exp,\n",
    "                \"model_size\": model_size,\n",
    "                \"accuracy\": d[\"correct\"],\n",
    "                \"confidence\": conf,\n",
    "                \"len_reason\": len(reason)\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44343ddb-f729-4481-bf98-bfd251f82d0a",
   "metadata": {},
   "source": [
    "## Accuracy and Confidence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fcfaf-4c10-414d-ac60-f80c98c990cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- audience-friendly plotting ----------\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Friendly labels for experiments and model sizes\n",
    "exp_order = [\"baseline\", \"1_4\", \"mid\", \"3_4\", \"end\"]\n",
    "exp_long = {\n",
    "    \"baseline\": \"No injection\",\n",
    "    \"1_4\":      \"Inject at 25% (early)\",\n",
    "    \"mid\":      \"Inject at 50% (middle)\",\n",
    "    \"3_4\":      \"Inject at 75% (late)\",\n",
    "    \"end\":      \"Inject at end\",\n",
    "}\n",
    "size_map   = {\"1.5\": \"1.5B\", \"7\": \"7B\", \"14\": \"14B\"}\n",
    "size_order = [\"1.5B\", \"7B\", \"14B\"]\n",
    "\n",
    "# Apply mappings\n",
    "df[\"where_injected\"] = pd.Categorical(df[\"exp\"].map(exp_long), categories=[exp_long[e] for e in exp_order], ordered=True)\n",
    "df[\"model_size_lbl\"] = pd.Categorical(df[\"model_size\"].map(size_map), categories=size_order, ordered=True)\n",
    "\n",
    "# Shared legend placement\n",
    "legend_kwargs = dict(ncol=len(size_order), loc=\"upper center\", bbox_to_anchor=(0.5, 1.15), frameon=False)\n",
    "\n",
    "# --- Accuracy plot ---\n",
    "plt.figure(figsize=(11, 6.8), dpi=140)\n",
    "ax = sns.barplot(\n",
    "    data=df, x=\"where_injected\", y=\"accuracy\", hue=\"model_size_lbl\",\n",
    "    estimator=np.mean, errorbar=\"se\", hue_order=size_order\n",
    ")\n",
    "ax.set_title(\"Accuracy vs. Where 'Doubt' Was Injected in the CoT\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(**legend_kwargs)\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_rotation(10)\n",
    "sns.despine()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # room for legend\n",
    "\n",
    "# --- Confidence plot ---\n",
    "plt.figure(figsize=(11, 6.8), dpi=140)\n",
    "ax = sns.barplot(\n",
    "    data=df, x=\"where_injected\", y=\"confidence\", hue=\"model_size_lbl\",\n",
    "    estimator=np.mean, errorbar=\"se\", hue_order=size_order\n",
    ")\n",
    "ax.set_title(\"Model Confidence vs. Doubt Injection Point\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"Confidence\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(**legend_kwargs)\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_rotation(10)\n",
    "sns.despine()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Optional: add a brief caption on either plot (uncomment if you want it)\n",
    "# plt.figtext(0.5, 0.005,\n",
    "#     \"Bars show mean across prompts; whiskers = ±1 SE. Baseline = no injection; 25%/50%/75% are from the start of the CoT.\",\n",
    "#     ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf995ba4-be4b-46d7-b952-f18f24e0921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- relative-to-baseline line charts ----------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Order + friendly labels\n",
    "exp_order = [\"baseline\", \"1_4\", \"mid\", \"3_4\", \"end\"]\n",
    "exp_long = {\n",
    "    \"baseline\": \"No injection (baseline)\",\n",
    "    \"1_4\":      \"Inject at 25% (early)\",\n",
    "    \"mid\":      \"Inject at 50% (middle)\",\n",
    "    \"3_4\":      \"Inject at 75% (late)\",\n",
    "    \"end\":      \"Inject at end\",\n",
    "}\n",
    "size_map   = {\"1.5\": \"1.5B\", \"7\": \"7B\", \"14\": \"14B\"}\n",
    "size_order = [\"1.5B\", \"7B\", \"14B\"]\n",
    "\n",
    "# Aggregate to means\n",
    "agg = (df.groupby([\"model_size\", \"exp\"])\n",
    "         .agg(accuracy=(\"accuracy\", \"mean\"),\n",
    "              confidence=(\"confidence\", \"mean\"))\n",
    "         .reset_index())\n",
    "\n",
    "# Label & ordering\n",
    "agg[\"model_size_lbl\"] = pd.Categorical(agg[\"model_size\"].map(size_map),\n",
    "                                       categories=size_order, ordered=True)\n",
    "agg[\"exp\"] = pd.Categorical(agg[\"exp\"], categories=exp_order, ordered=True)\n",
    "agg[\"where_injected\"] = pd.Categorical(agg[\"exp\"].map(exp_long),\n",
    "                                       categories=[exp_long[e] for e in exp_order],\n",
    "                                       ordered=True)\n",
    "\n",
    "# Baselines per model size\n",
    "base = (agg[agg[\"exp\"] == \"baseline\"]\n",
    "        .rename(columns={\"accuracy\": \"acc_base\", \"confidence\": \"conf_base\"})\n",
    "        [[\"model_size\", \"acc_base\", \"conf_base\"]])\n",
    "\n",
    "# Merge and compute ratios (guard against zero baselines)\n",
    "rel = agg.merge(base, on=\"model_size\", how=\"left\")\n",
    "rel[\"acc_rel\"]  = np.where(rel[\"acc_base\"]  > 0, rel[\"accuracy\"]  / rel[\"acc_base\"],  np.nan)\n",
    "rel[\"conf_rel\"] = np.where(rel[\"conf_base\"] > 0, rel[\"confidence\"] / rel[\"conf_base\"], np.nan)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6.5), dpi=140, sharex=True)\n",
    "\n",
    "# Accuracy ratio\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    data=rel.sort_values(\"exp\"),\n",
    "    x=\"where_injected\", y=\"acc_rel\", hue=\"model_size_lbl\",\n",
    "    hue_order=size_order, marker=\"o\", ax=ax\n",
    ")\n",
    "ax.axhline(1.0, ls=\"--\", lw=1, alpha=0.9)\n",
    "ax.set_title(\"Accuracy relative to baseline by injection point\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"Ratio to baseline (×)\")\n",
    "ax.legend(ncol=len(size_order), loc=\"upper center\",\n",
    "          bbox_to_anchor=(0.5, 1.18), frameon=False)\n",
    "for t in ax.get_xticklabels(): t.set_rotation(10)\n",
    "\n",
    "# Confidence ratio\n",
    "ax = axes[1]\n",
    "sns.lineplot(\n",
    "    data=rel.sort_values(\"exp\"),\n",
    "    x=\"where_injected\", y=\"conf_rel\", hue=\"model_size_lbl\",\n",
    "    hue_order=size_order, marker=\"o\", ax=ax\n",
    ")\n",
    "ax.axhline(1.0, ls=\"--\", lw=1, alpha=0.9)\n",
    "ax.set_title(\"Confidence relative to baseline by injection point\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"Ratio to baseline (×)\")\n",
    "ax.legend(\n",
    "    ncol=len(size_order), loc=\"upper center\",\n",
    "          bbox_to_anchor=(0.5, 1.18), frameon=False)\n",
    "for t in ax.get_xticklabels(): t.set_rotation(10)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a408d03-1710-4589-ac6c-af2ce78e8c09",
   "metadata": {},
   "source": [
    "## AUROC and Brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b13e9-7654-46c5-a684-6ad27e6da14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- AUROC & Brier score bar plots ----------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Friendly labels / order (same story labeling as before)\n",
    "exp_order = [\"baseline\", \"1_4\", \"mid\", \"3_4\", \"end\"]\n",
    "exp_long = {\n",
    "    \"baseline\": \"No injection\",\n",
    "    \"1_4\":      \"Inject at 25% (early)\",\n",
    "    \"mid\":      \"Inject at 50% (middle)\",\n",
    "    \"3_4\":      \"Inject at 75% (late)\",\n",
    "    \"end\":      \"Inject at end\",\n",
    "}\n",
    "size_map   = {\"1.5\": \"1.5B\", \"7\": \"7B\", \"14\": \"14B\"}\n",
    "size_order = [\"1.5B\", \"7B\", \"14B\"]\n",
    "\n",
    "# --- helpers ---\n",
    "def roc_auc_from_ranks(y_true, y_score):\n",
    "    \"\"\"\n",
    "    AUROC via rank formulation (no sklearn/scipy dependency).\n",
    "    Returns NaN if only one class present.\n",
    "    \"\"\"\n",
    "    y_true = pd.Series(y_true).astype(int)\n",
    "    if y_true.nunique() < 2:\n",
    "        return np.nan\n",
    "    ranks = pd.Series(y_score).rank(method=\"average\")  # average ties\n",
    "    n_pos = (y_true == 1).sum()\n",
    "    n_neg = (y_true == 0).sum()\n",
    "    sum_ranks_pos = ranks[y_true == 1].sum()\n",
    "    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg)\n",
    "    return float(auc)\n",
    "\n",
    "def group_metrics(g):\n",
    "    y_true = g[\"accuracy\"].astype(int).to_numpy()\n",
    "    y_hat  = g[\"confidence\"].astype(float).to_numpy()\n",
    "    brier = np.mean((y_hat - y_true) ** 2)\n",
    "    auc   = roc_auc_from_ranks(y_true, y_hat)\n",
    "    return pd.Series({\"auroc\": auc, \"brier\": brier})\n",
    "\n",
    "# Compute metrics per (model_size, exp)\n",
    "metrics = (df.groupby([\"model_size\", \"exp\"], as_index=False)\n",
    "             .apply(group_metrics)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# Apply nice labels & ordering\n",
    "metrics[\"where_injected\"] = pd.Categorical(\n",
    "    metrics[\"exp\"].map(exp_long),\n",
    "    categories=[exp_long[e] for e in exp_order],\n",
    "    ordered=True\n",
    ")\n",
    "metrics[\"model_size_lbl\"] = pd.Categorical(\n",
    "    metrics[\"model_size\"].map(size_map),\n",
    "    categories=size_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# --- AUROC bar plot ---\n",
    "plt.figure(figsize=(11, 6.8), dpi=140)\n",
    "ax = sns.barplot(\n",
    "    data=metrics, x=\"where_injected\", y=\"auroc\",\n",
    "    hue=\"model_size_lbl\", hue_order=size_order, errorbar=None\n",
    ")\n",
    "ax.axhline(0.5, ls=\"--\", lw=1, alpha=0.9)  # no-skill reference\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"AUROC vs. Where 'Doubt' Was Injected in the Chain-of-Thought\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"AUROC (higher is better)\")\n",
    "ax.legend(ncol=len(size_order), loc=\"upper center\",\n",
    "          bbox_to_anchor=(0.5, 1.14), frameon=False)\n",
    "for t in ax.get_xticklabels(): t.set_rotation(10)\n",
    "sns.despine()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# --- Brier score bar plot ---\n",
    "plt.figure(figsize=(11, 6.8), dpi=140)\n",
    "ax = sns.barplot(\n",
    "    data=metrics, x=\"where_injected\", y=\"brier\",\n",
    "    hue=\"model_size_lbl\", hue_order=size_order, errorbar=None\n",
    ")\n",
    "ax.set_title(\"Brier Score vs. Doubt Injection Point\")\n",
    "ax.set_xlabel(\"Injection point in the reasoning chain\")\n",
    "ax.set_ylabel(\"Brier score (lower is better)\")\n",
    "ax.legend(ncol=len(size_order), loc=\"upper center\",\n",
    "          bbox_to_anchor=(0.5, 1.14), frameon=False)\n",
    "for t in ax.get_xticklabels(): t.set_rotation(10)\n",
    "sns.despine()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5a3d3-8e8e-4c51-a582-6fe286d51043",
   "metadata": {},
   "source": [
    "## Len of CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9715cf-af80-4b7b-bc22-34fbba1ed80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "# Seaborn will create the legend from `hue` here\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"len_reason\",\n",
    "    hue=\"exp_label\",\n",
    "    hue_order=[\"baseline\", \"1/4\", \"mid\", \"3/4\", \"end\"],\n",
    "    bins=80,\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    "    multiple=\"layer\",\n",
    "    element=\"step\",\n",
    "    # fill=False,\n",
    "    binrange=(0, 3000),\n",
    "    linewidth=1.5,\n",
    "    legend=True,      # <- ensure legend is on\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Keep KDEs out of the legend to avoid duplicates\n",
    "sns.kdeplot(\n",
    "    data=df,\n",
    "    x=\"len_reason\",\n",
    "    hue=\"exp_label\",\n",
    "    hue_order=[\"baseline\", \"1/4\", \"mid\", \"3/4\", \"end\"],\n",
    "    common_norm=False,\n",
    "    clip=(0, 3000),\n",
    "    lw=2,\n",
    "    legend=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlim(0, 3000)\n",
    "ax.set_xlabel(\"Reasoning length\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Distribution of reasoning length by position\")\n",
    "\n",
    "# Move/style the existing legend\n",
    "sns.move_legend(ax, \"upper right\", title=\"Position\", frameon=False)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c6cd9-1275-4def-a716-bf1edd025b5d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d362551-bcd2-462e-a0c7-7f0157ab5e3c",
   "metadata": {},
   "source": [
    "## Confidence Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f1108-e553-4c02-bccc-9785cf5d4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "model_order = [\"1.5\", \"7\", \"14\"]\n",
    "palette = sns.color_palette(\"deep\", n_colors=len(model_order))\n",
    "color_map = dict(zip(model_order, palette))\n",
    "\n",
    "# Ensure types and clamp confidence\n",
    "df_use = df.copy()\n",
    "df_use[\"model_size\"] = pd.Categorical(df_use[\"model_size\"], categories=model_order, ordered=True)\n",
    "df_use[\"accuracy\"] = df_use[\"accuracy\"].astype(int)\n",
    "df_use[\"conf_pct\"] = (df_use[\"confidence\"].clip(0, 1) * 100)\n",
    "\n",
    "# Fixed, shared bin edges and labels\n",
    "edges = np.arange(0, 110, 10)  # 0,10,...,100\n",
    "df_use[\"conf_bin\"] = pd.cut(df_use[\"conf_pct\"], bins=edges, right=False, include_lowest=True)\n",
    "\n",
    "# Aggregate accuracy and counts per bin\n",
    "calib = (\n",
    "    df_use.groupby([\"model_size\", \"conf_bin\"], observed=True)\n",
    "          .agg(acc=(\"accuracy\", \"mean\"), n=(\"accuracy\", \"size\"))\n",
    "          .reset_index()\n",
    ")\n",
    "calib[\"acc_pct\"] = calib[\"acc\"] * 100\n",
    "calib[\"left\"]    = calib[\"conf_bin\"].apply(lambda iv: iv.left)\n",
    "calib[\"width\"]   = calib[\"conf_bin\"].apply(lambda iv: iv.right - iv.left)\n",
    "\n",
    "# ----------------- Figure layout -----------------\n",
    "fig = plt.figure(figsize=(16, 8), dpi=140)\n",
    "gs  = fig.add_gridspec(2, 3, height_ratios=[2.0, 1.2], hspace=0.45, wspace=0.3)\n",
    "\n",
    "# -------- Top row: calibration as histogram bars + count overlay (same bins) --------\n",
    "for i, ms in enumerate(model_order):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    sub = calib[calib[\"model_size\"] == ms]\n",
    "\n",
    "    # Calibration bars (Accuracy % per confidence bin)\n",
    "    ax.bar(\n",
    "        sub[\"left\"], sub[\"acc_pct\"], width=sub[\"width\"],\n",
    "        align=\"edge\", color=color_map[ms], edgecolor=\"white\", alpha=0.95\n",
    "    )\n",
    "\n",
    "    # Perfect calibration reference\n",
    "    ax.plot([0, 100], [0, 100], ls=\"--\", lw=1.2, color=\"gray\")\n",
    "\n",
    "    # # Twin axis: counts with identical bins (ensures perfect alignment)\n",
    "    # ax2 = ax.twinx()\n",
    "    # ax2.bar(\n",
    "    #     sub[\"left\"], sub[\"n\"], width=sub[\"width\"],\n",
    "    #     align=\"edge\", color=color_map[ms], alpha=0.18, edgecolor=\"none\"\n",
    "    # )\n",
    "    # ax2.set_ylabel(\"Frequency\")\n",
    "    # ax2.grid(False)\n",
    "\n",
    "    # Cosmetics\n",
    "    ax.set_title(f\"Model {ms}\")\n",
    "    ax.set_xlabel(\"Confidence (%)\")\n",
    "    ax.set_ylabel(\"Accuracy (%)\")\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xticks(edges)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=100))\n",
    "    sns.despine(ax=ax, right=False)\n",
    "    sns.despine(ax=ax2, left=True)\n",
    "\n",
    "# -------- Bottom row: confidence histograms side by side (same edges) --------\n",
    "for i, ms in enumerate(model_order):\n",
    "    axh = fig.add_subplot(gs[1, i])\n",
    "    sub_df = df_use[df_use[\"model_size\"] == ms]\n",
    "    axh.hist(sub_df[\"conf_pct\"], bins=edges, color=color_map[ms], edgecolor=\"white\")\n",
    "    axh.set_title(f\"Model {ms}\")\n",
    "    axh.set_xlabel(\"Confidence (%)\")\n",
    "    axh.set_ylabel(\"Frequency\")\n",
    "    axh.set_xlim(0, 100)\n",
    "    axh.set_xticks(edges)\n",
    "    sns.despine(ax=axh)\n",
    "\n",
    "fig.suptitle(\"Calibration as histograms (top) and confidence distributions (bottom)\", y=0.98, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d323e3-9b70-4ef0-9e0b-faa4783b8c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
